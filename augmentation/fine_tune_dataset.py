import os 
import os.path as osp
import math
import random
import time
import torch
from torch_geometric.data import Data
from torch_geometric.data import Dataset
# import torch_geometric.transforms as T
import torch.nn as nn

import numpy as np
import heapq
from heapq import heappush, heappop
from tqdm import tqdm

import numba
from numba.typed import List
from numba import njit, jit
from numpy import dot
from numpy.linalg import norm

from utils import utils
from augmentation.transformation import RandomEdgeMask,subspace, subsequence,MaskNode
from augmentation.dataset_generator import PairData
import re
import h5py

'''
This modifed original dataset generator.
It utilizes the h5py and hdf5 file dataset, generated by https://github.com/phermosilla/IEConv_proteins
Thanks to https://github.com/phermosilla/IEConv_proteins author.
'''

amino_acids_dict = {'ARG':0, 'HIS':1, 'LYS':2, 'ASP':3, 'GLU':4, 'SER':5, 'THR':6, 'ASN':7, 'GLN':8,
                'CYS':9, 'SEC':10, 'GLY':11, 'PRO':12, 'ALA':13, 'VAL':14, 'ILE':15, 'LEU':16, 'MET':17,
                'PHE':18, 'TYR':19, 'TRP':20, 'UNK':21, 'ASX':21, 'GLX':4} # 21 represents masked (unknown)

def one_hot_encoding(ele,size):
  one_hot_vector = [0]*size
  index = amino_acids_dict[ele]
  one_hot_vector[index] = 1
  return np.array([one_hot_vector])


def generate_node_feature(residue_name):
    start = True
    for ele in residue_name:
        test = one_hot_encoding(ele,22)
        if start:
            node_feature = test
            start = False
        else:
            node_feature = np.concatenate((node_feature,test), axis=0)
    return torch.from_numpy(node_feature).float()

class Fold_Dataset_GearNet_Edge(Dataset):
    def __init__(self,data_list, data_dir,phase= 'training', transform=None):
        '''
            data_dir = '/data/project/rw/codingtest/downstream_data/fold_data/
            phase = training, validation
        '''
        self.data_list = data_list  # 단백질 이름 리스트 
        self.data_dir = data_dir    # 단백질 파일 위치 
        self.processed = data_dir + 'processed/'
        self.transform = transform
        self.phase = phase
        maxIndex = 0
        self.classes_ = {}
        with open(osp.join(self.data_dir, "class_map.txt"), 'r') as mFile:
            for line in mFile:
                lineList = line.rstrip().split('\t')
                self.classes_[lineList[0]] = int(lineList[1])
                maxIndex = max(maxIndex, int(lineList[1]))
        
        # # classesList_ [a.1, a.2, ...,]
        # self.classesList_ = ["" for i in range(maxIndex+1)]
        # for key, value in classes_.items():
        #     self.classesList_[value] = key
        

    def __getitem__(self,index): # 상속 클래스 - 단백질 graph 생성 후 return
        # [d1v4wb_	a.1	a.1]
        # print(self.data_list[index])
        if osp.exists(osp.join(self.processed , self.data_list[index][0]+'.pt')):
            data = torch.load(osp.join(self.processed , self.data_list[index][0]+'.pt'))
            return data
        protein_path = osp.join(self.data_dir,self.phase,self.data_list[index][0]+".hdf5") # absolute path
        ############################################################################
        ## get label map 
        ############################################################################
        labels = self.data_list[index][-1]
        labels = torch.tensor([[self.classes_[labels]]], dtype=torch.int64)
        '''
        label
        tensor([[7],[6],[7],[8],[3],[6],[9],[3]])
        '''
        hf = h5py.File(protein_path,'r')
        ############################################################################
        ## get protein info
        ############################################################################
        n = hf.get("atom_names")
        n = np.array(n, dtype=str)
        result = np.where(n == 'CA')[0] # get indexes for CA 

        graph_3d = hf.get("atom_pos")
        graph_3d = np.array(graph_3d[0][result])

        residue_name = hf.get("atom_residue_names")
        residue_name = np.array(residue_name, dtype=str)[result]

        # print(residue_name)
        # # graph_3d = np.array([graph_3d])
        # print(graph_3d.shape)
        # # count = 0
        # for i in graph_3d:
        #     print(i[0],i[1],i[2])
   
        # ca_list = []
        # with open('{}'.format(protein_path)) as pdbfile:
        #     start = True
        #     for line in pdbfile:
        #         if line[:4] == 'ATOM' and line[13:15] == 'CA':
        #             ca_list.append(line) # 
        #             coordinate = [0] * 3
        #             coordinate[0], coordinate[1], coordinate[2] = float(line[31:38]),float(line[40:46]),float(line[47:54])
        #             if start:
        #                 graph_3d = np.array([coordinate])
        #                 start = False
        #             else:
        #                 coordinate = np.array([coordinate])
        #                 graph_3d = np.concatenate((graph_3d,coordinate), axis=0)

        # get node features
        node_feature = generate_node_feature(residue_name)
        # print(node_feature[idx_mask])

        num_residues = node_feature.size()[0]
        # print("num residues ", num_residues)

        # get sequential edges

        seq_edge,relation_type = utils.generate_seq_edges(num_residues)

        seq_edge = torch.from_numpy(np.array(seq_edge).transpose()).long()
        relation_type = torch.from_numpy(np.array(relation_type)).long()

        # get radius edges
        radius_edge, radius_type = utils.generate_radius_edges(graph_3d)

        radius_type = torch.from_numpy(np.array(radius_type)).long()
        radius_edge = torch.from_numpy(np.array(radius_edge).transpose()).long()

        # get knn edges 
        new_knn_edges, knn_type = utils.generate_knn_edges(graph_3d)
        new_knn_edges = torch.from_numpy(new_knn_edges).long()
        knn_type = torch.from_numpy(knn_type).long()

        # generate edge_index_dict 
        total_edge_index_dict = {}
        total_edge_index_dict[0] = seq_edge
        total_edge_index_dict[1] = radius_edge
        total_edge_index_dict[2] = new_knn_edges

        total_relation_dict = {}
        total_relation_dict[0] = relation_type
        total_relation_dict[1] = radius_type
        total_relation_dict[2] = knn_type


        # Generate edge features [node x 51 dim]
        edge_features_dict = {}
        for relation in range(0,3):    
            start = True
            sub_edge_feature = []
            for i,j in zip(total_edge_index_dict[relation][0], total_edge_index_dict[relation][1]):
                temp = np.array([])
                temp = np.hstack((temp, node_feature[i]))
                # print(node_feature[j])
                temp = np.hstack((temp, node_feature[j]))
                one_hot_relation_type = [0]* 7
                one_hot_relation_type[relation] = 1
                # one_hot_relation_type = np.array(one_hot_relation_type)
                temp = np.hstack((temp, one_hot_relation_type))
                # print(one_hot_relation_type)
                seq = [abs(i-j)]
                temp = np.hstack((temp, seq))
                # print(seq)
                dis = [utils.calculate_distance(graph_3d[i],graph_3d[j])]
                temp = np.hstack((temp, dis))
                temp = np.array([temp])
                # print(temp.shape)
                if start:
                    sub_edge_feature = temp
                    start = False
                else:
                    sub_edge_feature = np.concatenate((sub_edge_feature,temp), axis=0)
            start = True
            edge_features_dict[relation] = torch.from_numpy(sub_edge_feature).float()
        
        # Integrating all graph information
        edge_index = []
        edge_feature = []
        relation = []
        start = True
        for i in range(3):
            if start:
                edge_index = total_edge_index_dict[i] # 2 x 447
                edge_feature = edge_features_dict[i] # 447 x 51
                relation = total_relation_dict[i] # 449
                start = False
            else:
                edge_index_tmp = total_edge_index_dict[i] # 2 x 447
                edge_feature_tmp = edge_features_dict[i] # 447 x 51
                relation_tmp = total_relation_dict[i] # 449
                edge_index = torch.cat((edge_index,edge_index_tmp), axis=1)
                edge_feature = torch.cat((edge_feature, edge_feature_tmp))
                relation = torch.cat((relation, relation_tmp))

        edge_message_index,edge_message_relation = utils.generate_edge_graph(edge_index.numpy(), edge_feature.numpy())
        edge_message_index = torch.from_numpy(np.array(edge_message_index).transpose()).long()
        edge_message_relation = torch.from_numpy(np.array(edge_message_relation)).long()
        # edge_info = Data(x=data[i].edge_attr,edge_index = edge_index,edge_type = edge_type,num_nodes = data[i].edge_attr.size()[0])

        data = Data(x = node_feature, edge_index = edge_index, edge_type=relation, edge_attr= edge_feature, pos=graph_3d)
        data.edge_message_index = edge_message_index
        data.edge_message_relation = edge_message_relation
        data.label = labels

        # x=None, edge_index=None, edge_attr=None, y=None,pos=None, norm=None, face=None, **kwargs
        # data = PairData(edge_index, node_feature , relation, node_feature.size()[0],edge_message_index, edge_feature, edge_message_relation,edge_feature.size()[0])
        # data.label = labels
        torch.save(data,osp.join(self.processed , self.data_list[index][0]+'.pt'))
        return data


    def shuffle(self):
        prev = self.data_list.copy()
        random.shuffle(prev)
        self.data_list = prev

    def __len__(self):
        return len(self.data_list)




class Reaction_Dataset_GearNet_Edge(Dataset):
    def __init__(self,data_list, data_dir,phase= 'training', transform=None):
        '''
            data_dir = '/data/project/rw/codingtest/downstream_data/reaction_data/data'
            phase = training, validation
        '''
        self.data_list = data_list  # 단백질 이름 리스트 
        self.data_dir = data_dir + 'data/'    # 단백질 파일 위치 
        self.chains_dir = data_dir + 'chain_functions.txt'
        self.processed = data_dir + 'processed/'
        self.transform = transform
        self.phase = phase

        # # Load the functions.
        '''
            [name_of_protein] = label
        '''
        self.protFunct_ = {}
        with open(self.chains_dir, 'r') as mFile:
            for line in mFile:
                splitLine = line.rstrip().split(',')
                self.protFunct_[splitLine[0]] = int(splitLine[1])
        

    def __getitem__(self,index): # 상속 클래스 - 단백질 graph 생성 후 return
        '''
        data_dir = '/data/project/rw/codingtest/downstream_data/reaction_data/data/'
        data_list = ['2pmo.X','2pmn.X','2kio.A','1w1n.A','2kit.A','5ygq.B','3knv.A','6g4j.A']
        '''
        # n = '5lf1.b'
        # a,b = self.data_list[index].split('.')
        # if 97 <= ord(b) <= 122:
        #     b = chr(ord(b) - 32)
        # self.data_list[index] = a +'.'+b 
        # if osp.exists(osp.join(self.processed , self.data_list[index]+'.pt')):
        #     data = torch.load(osp.join(self.processed , self.data_list[index]+'.pt'))
        #     return data

        # if osp.exists(osp.join(self.data_dir , self.data_list[index]+'.hdf5')):

        protein_path = osp.join(self.data_dir,self.data_list[index]+".hdf5") # absolute path
        # print(protein_path)
        if not osp.exists(protein_path):
            a,b = self.data_list[index].split('.')
            if 97 <= ord(b) <= 122:
                b = chr(ord(b) - 32)
            elif 65 <= ord(b) <= 90:
                b= chr(ord(b) + 32)
            item = a +'.'+b
            # print(item)
            if osp.exists(osp.join(self.data_dir , item+'.hdf5')): 
                protein_path = osp.join(self.data_dir,item+".hdf5") # absolute path
        # print(self.data_list[index])
        ############################################################################
        ## get label map 
        labels = self.protFunct_[self.data_list[index]]
        labels = torch.tensor([[labels]], dtype=torch.int64)
        ############################################################################
        # label = torch.tensor([3], dtype= torch.int64)
        # print(labels)
        '''
        label
        tensor([[7],[6],[7],[8],[3],[6],[9],[3]])
                y_one_hot = torch.zeros(batch_size,class_num).scatter_(1,label,1)
                y_one_hot = torch.zeros(batch_size,1195).scatter_(1,label,1)
        '''
        hf = h5py.File(protein_path)
        ############################################################################
        ## get protein info
        ############################################################################
        n = hf.get("atom_names")
        n = np.array(n, dtype=str)
        result = np.where(n == 'CA')[0] # get indexes for CA 

        graph_3d = hf.get("atom_pos")
        graph_3d = np.array(graph_3d[0][result])

        residue_name = hf.get("atom_residue_names")
        residue_name = np.array(residue_name, dtype=str)[result]

        # get node features
        node_feature = generate_node_feature(residue_name)
        # print(node_feature[idx_mask])

        num_residues = node_feature.size()[0]
        # print("num residues ", num_residues)

        # get sequential edges

        seq_edge,relation_type = utils.generate_seq_edges(num_residues)

        seq_edge = torch.from_numpy(np.array(seq_edge).transpose()).long()
        relation_type = torch.from_numpy(np.array(relation_type)).long()

        # get radius edges
        radius_edge, radius_type = utils.generate_radius_edges(graph_3d)

        radius_type = torch.from_numpy(np.array(radius_type)).long()
        radius_edge = torch.from_numpy(np.array(radius_edge).transpose()).long()

        # get knn edges 
        new_knn_edges, knn_type = utils.generate_knn_edges(graph_3d)
        new_knn_edges = torch.from_numpy(new_knn_edges).long()
        knn_type = torch.from_numpy(knn_type).long()

        # generate edge_index_dict 
        total_edge_index_dict = {}
        total_edge_index_dict[0] = seq_edge
        total_edge_index_dict[1] = radius_edge
        total_edge_index_dict[2] = new_knn_edges

        total_relation_dict = {}
        total_relation_dict[0] = relation_type
        total_relation_dict[1] = radius_type
        total_relation_dict[2] = knn_type


        # Generate edge features [node x 51 dim]
        edge_features_dict = {}
        for relation in range(0,3):    
            start = True
            sub_edge_feature = []
            for i,j in zip(total_edge_index_dict[relation][0], total_edge_index_dict[relation][1]):
                temp = np.array([])
                temp = np.hstack((temp, node_feature[i]))
                # print(node_feature[j])
                temp = np.hstack((temp, node_feature[j]))
                one_hot_relation_type = [0]* 7
                one_hot_relation_type[relation] = 1
                # one_hot_relation_type = np.array(one_hot_relation_type)
                temp = np.hstack((temp, one_hot_relation_type))
                # print(one_hot_relation_type)
                seq = [abs(i-j)]
                temp = np.hstack((temp, seq))
                # print(seq)
                dis = [utils.calculate_distance(graph_3d[i],graph_3d[j])]
                temp = np.hstack((temp, dis))
                temp = np.array([temp])
                # print(temp.shape)
                if start:
                    sub_edge_feature = temp
                    start = False
                else:
                    sub_edge_feature = np.concatenate((sub_edge_feature,temp), axis=0)
            start = True
            edge_features_dict[relation] = torch.from_numpy(sub_edge_feature).float()
        
        # Integrating all graph information
        edge_index = []
        edge_feature = []
        relation = []
        start = True
        for i in range(3):
            if start:
                edge_index = total_edge_index_dict[i] # 2 x 447
                edge_feature = edge_features_dict[i] # 447 x 51
                relation = total_relation_dict[i] # 449
                start = False
            else:
                edge_index_tmp = total_edge_index_dict[i] # 2 x 447
                edge_feature_tmp = edge_features_dict[i] # 447 x 51
                relation_tmp = total_relation_dict[i] # 449
                edge_index = torch.cat((edge_index,edge_index_tmp), axis=1)
                edge_feature = torch.cat((edge_feature, edge_feature_tmp))
                relation = torch.cat((relation, relation_tmp))

        data = Data(x = node_feature, edge_index = edge_index, edge_type=relation, edge_attr= edge_feature, pos=graph_3d)

        edge_message_index,edge_message_relation = utils.generate_edge_graph(edge_index.numpy(), edge_feature.numpy())
        edge_message_index = torch.from_numpy(np.array(edge_message_index).transpose()).long()
        edge_message_relation = torch.from_numpy(np.array(edge_message_relation)).long()
        # edge_info = Data(x=data[i].edge_attr,edge_index = edge_index,edge_type = edge_type,num_nodes = data[i].edge_attr.size()[0])
        data.edge_message_index = edge_message_index
        data.edge_message_relation = edge_message_relation
        data.label = labels

        # x=None, edge_index=None, edge_attr=None, y=None,pos=None, norm=None, face=None, **kwargs
        # data = PairData(edge_index, node_feature , relation, node_feature.size()[0],edge_message_index, edge_feature, edge_message_relation,edge_feature.size()[0])
        # data.label = labels
        # torch.save(data,osp.join(self.processed , self.data_list[index]+'.pt'))
        return data


    def shuffle(self):
        prev = self.data_list.copy()
        random.shuffle(prev)
        self.data_list = prev

    def __len__(self):
        return len(self.data_list)